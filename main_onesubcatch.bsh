#!/bin/bash

# This adapts the approach used in Tyne catchment for Tweed
g.region -a zoom=tweed_ihu_50m res=50

#######################################
# Use create_subcatchments.bsh to define number of subcatchments
# based on threshold value. This initial run uses threshold of
# 50,000 which gives 26 subcatchments.

subcatch_totno='26'
echo 'total number of subcatchments being analysed is ' $subcatch_totno
max_subcatch_no=$subcatch_totno

subcatch_no='7'
echo 'initialised subcatchment number is set to' $subcatch_no
max_subcatch_no=$subcatch_no # Just for debugging one subcatchment at a time

# Latitude in degrees (needed for evapotranspiration calculation)
latitude='55'
echo 'latitude is set to' $latitude

## Input file mean daily temperature.  Each row a day, each column a catchment,
## i.e. 15 cols in total for the Tyne dataset 7 columns for Jim's Enigma dataset
## This will need making more automatic for Tweed
#mean_temp_csv_file='tyne_meantemp_allsubcatch30.csv'
#echo 'temperature file used is' $mean_temp_csv_file
#
## Input file mean daily rainfall.  Each row a day, each column a catchment,
## i.e. 15 cols in total for the Tyne dataset, 7 columns for Jim's Enigma dataset
#mean_rain_csv_file='tyne_cleanrain_allsubcatch30.csv'
#echo 'rainfaill file used is ' $mean_rain_csv_file
#
## Input file with rules for splitting up longest flow path into 10% sections
#segment_rules='segment_rules.txt'
#echo 'segment rules file for splitting flow into sections is' $segment_rules

# Input template of topmod_parameters
topmod_params_init='topmod_params_init.txt'
echo 'topmodel paramenters file used is' $topmod_params_init

# Input raster map containing DEM for whole study area
topmod_demraw='tweed_ihdtm_50m'
echo 'raster map of DEM used is' $topmod_demraw

# Input raster map containing all (sub)catchments for study. 
topmod_allcatch='tweed_ihu_50m' # aligns better
echo 'raster map containing all catchments is' $topmod_allcatch

# Input raster map (sub)catchments.  Each (sub)catchment has a separate number
topmod_subcatch='tweed_subcatchments'
echo 'raster map of subcatchment used is' $topmod_subcatch

# Number of days to be modelled
# If using NRFA data it stops in September 2019 for latest upload
ntimesteps=`scripts/get_num_days.py 2010-01-01 2019-09-30`

echo "If happy with input specification hit return to continue"
# read
#### End of input variable specification ####
#############################################

d.mon stop=wx1
d.mon start=wx1

#while [ $subcatch_no -le $subcatch_totno ]
#while [ $subcatch_no -le $max_subcatch_no ] # debugging one catchmnt
#do

echo "****************************************"
echo $subcatch_no
d.erase

# Remove MASK if present
r.mask -r

# Set region to cover all study catchments
g.region -a rast=$topmod_allcatch res=50


# Set MASK to correct subcatchment; topmodel will now be run only in the area
# of topmod_onecatch 
g.remove -f type=raster name=topmod_onecatch
r.mapcalc expression="topmod_onecatch=if($topmod_subcatch==$subcatch_no,1,null())" --overwrite
g.region -a zoom=topmod_onecatch res=50
# Need resolution to help clean longest flow path vector
resolution=`g.region -p | grep nsres | awk '{print $2}'`
d.mon sel=wx1
r.mask topmod_onecatch --quiet


# Encountered problems creating reliable stream network from original DEM
# For Campy work used r.fill.dem first, just on the IHU (subcatchment for
# Campy. Try the same here.
r.mapcalc expression=ihu_dem=ceh_ihdtm_hght_50m --overwrite
r.colors map=ihu_dem color=elevation

# Coords just downstream of NRFA 21018 but we should
# be able to use stream_outlets map to guide us before comparing
# with NRFA
# Use d.where | awk '{printf "%f\%f\point\n", $1, $2}' | v.in.ascii ...
# if using a d.mon screen
#echo "348577.63|631535.35|point" | v.in.ascii input=- output=ihu_outlet columns='x double precision, y double precision, label varchar(20)' --overwrite
# Outlet coordinates for this subcatchment
outlet_coords=`v.db.select -c stream_outlets layer=2 where="lcat==$subcatch_no" separator=comma | cut -d"," -f4,5`
echo $outlet_coords

# Given problems with both stream network reliability from CEH and DEM, try
# filling and recreating.
#g.region -a res=50
r.resamp.interp input=ihu_dem output=ihu_dem2 --overwrite
r.fill.dir input=ihu_dem output=ihu_demfill direction=ihu_demdir areas=ihu_dem_problems --overwrite
# If subcatch includes the River Tweed at its lower reaches, it is classed
# as -1000
r.mapcalc expression="ihu_demfill=if(ihu_demfill==-1000,null(),ihu_demfill)" --overwrite
r.colors ihu_demfill color=elevation

# Now try and display streams
r.stream.extract elevation=ihu_demfill stream_raster=ihu_watershed_streams direction=ihu_fdir threshold=1 --verbose --overwrite
d.rast ihu_watershed_streams
r.stream.order stream_rast=ihu_watershed_streams direction=ihu_fdir strahler=ihu_strahler --overwrite
d.erase
d.rast ihu_strahler

output_stream=`r.stats -n ihu_strahler | tail -1`
echo 'the highest stream number found is' $output_stream

r.mapcalc expression="output_stream_dem=if(ihu_strahler==$output_stream, ihu_demfill,null())" --overwrite
r.stats -gn output_stream_dem > output_flow.txt

# Assume output E and N coords are at minimum DEM of this stream
E_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $1}'`
N_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $2}'`
echo $E_outflow
echo $N_outflow
echo $outlet_coords


echo 'easting and northing coordinates for outflow are respectively' $E_outflow, $N_outflow
r.accumulate direction=ihu_fdir subwatershed=ihu_watershed accumulation=facc longest_flow_path=ihu_lfp coordinates=$E_outflow,$N_outflow --overwrite
d.vect tweed_rivers
d.vect ihu_lfp color=blue width=5



# 2. TOPMODEL TOPOGRAPHIC INDEX
r.topidx input=ihu_demfill output=ihu_topidx --overwrite
r.mapcalc expression="ihu_topidx_watershed=if(isnull(ihu_watershed),null(),ihu_topidx)" --overwrite
d.rast ihu_topidx_watershed
# NOTE: topidx_watershed is not calculated for reservoirs (flat areas)

# For later when setting up the topmodel_param.txt file we need the distance
# along each subwatershed. This needs the stream network to be 'burnt' into
# the relevant dem as per the tutorial.
r.mapcalc expression="ihu_dem_burned=if(isnull(ihu_watershed_streams),ihu_demfill,-9999)" --overwrite
r.watershed elevation=ihu_dem_burned drainage=ihu_fdir --overwrite
d.rast ihu_fdir

# Given problems with outlet map earlier, create one based on stream
# network outflow point
echo "1|$E_outflow|$N_outflow|output" | v.in.ascii in=- x=2 y=3 cat=1 columns='cat int, x double precision, y double precision, label varchar(20)' out=ihu_outlet --overwrite

# Now we can delineate the watershed and display the longest flow path
# Note: r.accumulate may neet to be installed with g.extension
r.accumulate direction=ihu_fdir outlet=ihu_outlet subwatershed=ihu_watershed accumulation=ihu_facc longest_flow_path=ihu_lfp --overwrite

# Convert the watershed raster to vector.
r.to.vect input=ihu_watershed type=area output=ihu_watershed --overwrite



# 3. TOPMODEL PARAMETERS
# suboutlets.txt created with divisions every 10% along lfp
v.segment input=ihu_lfp rules=suboutlets.txt output=ihu_suboutlets --overwrite
r.accumulate direction=ihu_fdir outlet=ihu_suboutlets subwatershed=ihu_subwatersheds --overwrite
d.erase
d.rast ihu_subwatersheds
d.vect ihu_lfp color=blue width=3
d.vect ihu_suboutlets fill_color=red icon=basic/circle size=10
d.vect ihu_strahler

# Note that this subcatchment is really unevenly split (just like the online
# tutorial) and so should be modelled as a multi-subwatershed model with two
# separate r.topmodel models. However stick with one model for now, as with
# the tutorial.


# Creating the last set of the parameters input file
# Calculate the length of the LFP
v.db.addtable map=ihu_lfp
v.to.db map=ihu_lfp option=length units=meters columns=length_m
v.db.select map=ihu_lfp
# Value we want is 2nd line when printed vertically
lfp_length=`v.db.select -c map=ihu_lfp format=vertical | sed -n '2p'`
echo $lfp_length

# Add column with distance of each ihu_suboutlet from main ihu_outlet
v.db.addtable map=ihu_suboutlets
v.db.addcolumn map=ihu_suboutlets columns="distance_m real"
v.db.update map=ihu_suboutlets column=distance_m query_column="cat*$lfp_length/10"

# The cumulative area ratios of the subwatersheds can be obtained from the flow
# accumulation raster. Add facc values to ihu_suboutlets and ihu_outlet
v.what.rast map=ihu_suboutlets raster=facc column=facc
v.what.rast map=ihu_outlet raster=facc column=facc
v.db.select map=ihu_outlet
# Value we want is 5th line when printed vertically
watershed_cells=`v.db.select -c map=ihu_outlet format=vertical | sed -n '5p'`
echo $watershed_cells

# The total number of cells within the watershed is stored in the
# watershed_cells script variable. Divide the facc column in the suboutlets
# vector by this number to obtain the cumulative area ratios.
v.db.addcolumn map=ihu_suboutlets columns="area_ratio real"
v.db.update map=ihu_suboutlets column=area_ratio query_column="1-facc/$watershed_cells."
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab
# Just make sure to append a . after $watershed_cells to force a floating-point
# division.

# Now modify topmodel input parameters template with these data
topmod_params_init='topmod_params_init.txt'
echo 'topmodel paramenters file used is' $topmod_params_init
# topmod_params_init is a template; simply add correct area on line 7 and area
# ratios First 6 lines the same for everything
head --lines 6 $topmod_params_init > topmod_params.txt
# Catchment area
r.stats -an ihu_watershed --quiet | awk '{print $2}' >> topmod_params.txt
# Next 54 lines of template same for everything
tail --lines 54 $topmod_params_init >> topmod_params.txt
echo "0.0       0.0" >> topmod_params.txt
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab >> topmod_params.txt
echo "$lfp_length       1.0" >> topmod_params.txt

# 4.TOPMODEL topidxstats
# r.topmodel provides a preprocessing flag -p to generate a topidxstats file
# from a topidx raster created by r.topidx. The following command calculates
# statistics about topographic indices in the topidx raster by splitting the
# entire range into 30 classes:
r.topmodel -p topidx=ihu_topidx ntopidxclasses=30 outtopidxstats=topidxstats.txt --overwrite

# Each line starts with the upper limit of a topographic index range whose
# ratio is recorded in the next line in the second column with its lower
# limit in the first column. For example, topographic indices between 16.67
# and 17.09 covers the 1.742e-4% of the watershed.
#
# These pairs are sorted by the topographic index in an descending order.
# Since the first line represents the maximum topographic index, its second
# column must always be 0.

# 5. WEATHER DATA
# There are really too few weather NCDC stations in our area. Have created
# spatio-temporal daily temperature and rainfall datasets from UKHAD at 1 km
# from 2010 to 2019 (currently on bces-01 in uk_met mapset).
# Need to get average rainfall for target subcatchment ihu_watershed
r.mapcalc expression="MASK=ihu_watershed" --overwrite
g.region -a zoom=MASK res=1000
t.rast.mapcalc inputs=wader_rainfall_daily@PERMANENT output=tmp_ihu_rainfall basename=tmp_ihu_rainfall expression="tmp_ihu_rainfall=wader_rainfall_daily" nprocs=8 --overwrite
t.rast.univar -u tmp_ihu_rainfall | cut -d'|' -f4 > ihu_rainfall.txt 
t.remove -d -f tmp_ihu_rainfall
r.mask -r
r.mask raster=ihu_watershed
# Convert rainfall to m / day
awk '{printf("%.6f\n", ($1/1000))}' ihu_rainfall.txt > ihu_rainfall.txt2
mv ihu_rainfall.txt2 input_rain.txt
g.region -a zoom=MASK res=50

# For PET use the USGS for now, but this is at 1-minute resolution. Might
# be possible to use EA PET data but this is England-only. Would need to
# create simple model to get it over the border, but in practice the PET
# is fairly uniform across the whole region on any given day so probably
# ok with USGS PET
# Run this in epsg4326 location; just run once
# Centroid of whole Wader region in epsg4326 location; next only needs running
# once for whole Wader region as assume roughly the same in each subcatchment
# -2.4630233218518516,55.558426188481484
#for i in $(g.list type=raster pattern=et*); do
#    r.what map=$i coordinates=-2.4630233218518516,55.558426188481484 | sed 's/.*|/0.00001*/' | bc
#done > usgs_pet.txt

# Back in OS projection
# Best NRFA station is measuring Ettrick Water at Lindean id 21007
# Note: this actually runs to 30th Sept 2019 via rnrfa. NRFA website
# gives to current date, but on download also ends 30th Sept.
# See R script nrfa_download_flow.R for simple download of a station.
# saved in obs.txt to match tutorial
# Need to change to something easier later!
nrfa_station_id=21018
Rscript nrfa_download_flow.R $nrfa_station_id 2010-01-01 2019-12-31 obs.txt
echo "# From nrfa_download_flow.R for $nrfa_station_id ideal start_date=2010-01-01 end_date=2020-12-31" > tmp.txt
echo "# Q [m^3/d]" >> tmp.txt
cat obs.txt >> tmp.txt
mv tmp.txt obs.txt


# Need to assemble rainfall and PET into a single file
# original online tutorial creates a file called input_evap.txt for
# rainfall AND evapotranspiration. A bit confusing, so will rename
# later!
rain_evap_file="input_rain_evap.txt"
echo "# Generated by from ihu_topmodel.bsh start_date=2010-01-01 end_date=2019-12-31" > $rain_evap_file
echo "# dt [h]: Time step" >> $rain_evap_file
echo "24" >> $rain_evap_file
echo "" >> $rain_evap_file
echo "################################################################################" >> $rain_evap_file
echo "# R [m/dt]:  Rainfall" >> $rain_evap_file
echo "# Ep [m/dt]: Potential evapotranspiration" >> $rain_evap_file
echo "" >> $rain_evap_file
echo "# R Ep" >> $rain_evap_file
paste -d " " input_rain.txt usgs_pet.txt >> $rain_evap_file



## Calibration - skip for now
## We just use the evap file, not pet
## As NRFA only goes to September 2019, use this as max date
## get the number of days for calibration period
##scripts/get_num_days.py 2010-01-01 2015-12-31
## Returns 2191
#head -9 input_evap.txt > input_c_evap.txt
#tail +10 input_evap.txt | sed '2191q' >> input_c_evap.txt
#head -2 obs.txt > obs_c.txt
#tail +3 obs.txt | sed '2191q' >> obs_c.txt
## For validation skip to january 1st 2015
##scripts/get_num_days.py 2010-01-01 2014-12-31
## Returns 1826
## Skip the first 1,826 records from input_evap.txt, input_pet.txt, and obs.txt.
## BUT the NRFA data sometimes incomplete, so have to check that filesizes
## match so need to check number of days to end of NRFA data
##get_num_days.py 2015-01-01 2019-09-30
## Returns 1734
#head -9 input_evap.txt > input_v_evap.txt
#tail +1836 input_evap.txt | sed '1734q' >> input_v_evap.txt
#head -2 obs.txt > obs_v.txt
#tail +1829 obs.txt | sed '1734q' >> obs_v.txt
#
#
## Before running the calibration script in the data folder copy the
## topmodel_params.txt to data/params.txt

# Run r.topmodel
r.topmodel param=topmod_params.txt topidxstats=topidxstats.txt input=$rain_evap_file output=topmod_output.txt --overwrite
tail -n +66 topmod_output.txt > topmod_output_for_R.txt
tail -n +3  obs.txt           > obs_for_R.txt

## Original approach used in Tyne but probably not relevant for Tweed
## Post-process results to make them easier to read into R
#tail -n +63 topmod_output.txt > topmod_output_tmp.txt
#cat topmod_output_tmp.txt | awk '{print $1, $2, $3, $4, $5, $6, $7}' > topmod_output_R.txt
#rm topmod_output_tmp.txt
#Rscript postprocess.R $mean_rain_csv_file $ntimesteps $subcatch_no $subcatch_totno

