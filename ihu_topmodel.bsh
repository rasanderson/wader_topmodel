#!/bin/bash

# This adapts the approach used in Tyne catchment for Tweed
g.region -a zoom=tweed_ihu_groups_50m res=50

#######################################
# Note that Tweed has 8 IHU groups. These are much bigger than
# the ones we worked with for the Tyne, so we may have to 
# sub-divide. Tyne had optimum at 20

subcatch_totno='8'
echo 'total number of subcatchments being analysed is ' $subcatch_totno
max_subcatch_no=$subcatch_totno

subcatch_no='4'
echo 'initialised subcatchment number is set to' $subcatch_no
max_subcatch_no=$subcatch_no # Just for debugging one subcatchment at a time

# Latitude in degrees (needed for evapotranspiration calculation)
latitude='55'
echo 'latitude is set to' $latitude

## Input file mean daily temperature.  Each row a day, each column a catchment,
## i.e. 15 cols in total for the Tyne dataset, 7 columns for Jim's Enigma dataset
#mean_temp_csv_file='tyne_meantemp_allsubcatch30.csv'
#echo 'temperature file used is' $mean_temp_csv_file
#
## Input file mean daily rainfall.  Each row a day, each column a catchment,
## i.e. 15 cols in total for the Tyne dataset, 7 columns for Jim's Enigma dataset
#mean_rain_csv_file='tyne_cleanrain_allsubcatch30.csv'
#echo 'rainfaill file used is ' $mean_rain_csv_file
#
## Input file with rules for splitting up longest flow path into 10% sections
#segment_rules='segment_rules.txt'
#echo 'segment rules file for splitting flow into sections is' $segment_rules

# Input template of topmod_parameters
topmod_params_init='topmod_params_init.txt'
echo 'topmodel paramenters file used is' $topmod_params_init

# Input raster map containing DEM for whole study area
topmod_demraw='tweed_ihdtm_50m'
echo 'raster map of DEM used is' $topmod_demraw

# Input raster map containing all (sub)catchments for study. 
topmod_allcatch='tweed_ihu_50m' # aligns better
echo 'raster map containing all catchments is' $topmod_allcatch

# Input raster map (sub)catchments.  Each (sub)catchment has a separate number
topmod_subcatch='tweed_ihu_groups_50m'
echo 'raster map of subcatchment used is' $topmod_subcatch

# Number of days to be modelled
# If using NRFA data it stops in September 2019 for latest upload
ntimesteps=`scripts/get_num_days.py 2010-01-01 2019-09-30`

echo "If happy with input specification hit return to continue"
read
#### End of input variable specification ####
#############################################

d.mon stop=wx1
d.mon start=wx1

#while [ $subcatch_no -le $subcatch_totno ]
while [ $subcatch_no -le $max_subcatch_no ] # debugging one catchmnt
do

echo "****************************************"
echo $subcatch_no
d.erase

# Remove MASK if present
r.mask -r

# Set region to cover all study catchments
g.region rast=$topmod_allcatch res=50


# Set MASK to correct subcatchment; topmodel will now be run only in the area
# of topmod_onecatch 
g.remove -f type=raster name=topmod_onecatch
r.mapcalc expression="topmod_onecatch=if($topmod_subcatch==$subcatch_no,1,null())" --overwrite
g.region -a zoom=topmod_onecatch res=50
# Need resolution to help clean longest flow path vector
resolution=`g.region -p | grep nsres | awk '{print $2}'`
d.mon sel=wx1
r.mask topmod_onecatch --quiet


# Encountered problems creating reliable stream network from original DEM
# For Campy work used r.fill.dem first, just on the IHU (subcatchment for
# Campy. Try the same here.
r.mapcalc expression=ihu_dem=ceh_ihdtm_50m --overwrite
r.colors map=ihu_dem color=elevation

# Coords just downstream of NRFA 12 (21007)
# Use d.where | awk '{printf "%f\%f\point\n", $1, $2}' | v.in.ascii ...
# if using a d.mon screen
echo "348577.63|631535.35|point" | v.in.ascii input=- output=ihu_outlet columns='x double precision, y double precision, label varchar(20)' --overwrite

# Given problems with both stream network reliability from CEH and DEM, try
# filling and recreating.
g.region -a res=50
r.resamp.interp input=ihu_dem output=ihu_dem2 --overwrite
r.fill.dir input=ihu_dem output=ihu_demfill direction=ihu_demdir areas=ihu_dem_problems --overwrite
# If subcatch includes the River Tweed at its lower reaches, it is classed
# as -1000
r.mapcalc expression="ihu_demfill=if(ihu_demfill==-1000,null(),ihu_demfill)" --overwrite
r.colors ihu_demfill color=elevation

# Now try and display streams
r.stream.extract elevation=ihu_demfill stream_raster=ihu_watershed_streams direction=ihu_fdir threshold=1 --verbose --overwrite
d.rast ihu_watershed_streams
r.stream.order stream_rast=ihu_watershed_streams direction=ihu_fdir strahler=ihu_strahler --overwrite
d.erase
d.rast ihu_strahler

output_stream=`r.stats -n ihu_strahler | tail -1`
echo 'the highest stream number found is' $output_stream

r.mapcalc expression="output_stream_dem=if(ihu_strahler==$output_stream, ihu_demfill,null())" --overwrite
r.stats -gn output_stream_dem > output_flow.txt

# Assume output E and N coords are at minimum DEM of this stream
E_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $1}'`
N_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $2}'`

echo 'easting and northing coordinates for outflow are respectively' $E_outflow, $N_outflow
r.accumulate direction=ihu_fdir subwatershed=ihu_watershed accumulation=facc longest_flow_path=ihu_lfp coordinates=$E_outflow,$N_outflow --overwrite
d.vect tweed_rivers
d.vect ihu_lfp color=blue width=5



# 2. TOPMODEL TOPOGRAPHIC INDEX
r.topidx input=ihu_demfill output=ihu_topidx --overwrite
r.mapcalc expression="ihu_topidx_watershed=if(isnull(ihu_watershed),null(),ihu_topidx)" --overwrite
d.rast ihu_topidx_watershed
# NOTE: topidx_watershed is not calculated for reservoirs (flat areas)

# For later when setting up the topmodel_param.txt file we need the distance
# along each subwatershed. This needs the stream network to be 'burnt' into
# the relevant dem as per the tutorial.
r.mapcalc expression="ihu_dem_burned=if(isnull(ihu_watershed_streams),ihu_demfill,-9999)" --overwrite
r.watershed elevation=ihu_dem_burned drainage=ihu_fdir --overwrite
d.rast ihu_fdir

# Given problems with outlet map earlier, create one based on stream
# network outflow point
echo "1|$E_outflow|$N_outflow|output" | v.in.ascii in=- x=2 y=3 cat=1 columns='cat int, x double precision, y double precision, label varchar(20)' out=ihu_outlet --overwrite

# Now we can delineate the watershed and display the longest flow path
# Note: r.accumulate may neet to be installed with g.extension
r.accumulate direction=ihu_fdir outlet=ihu_outlet subwatershed=ihu_watershed accumulation=ihu_facc longest_flow_path=ihu_lfp --overwrite

# Convert the watershed raster to vector.
r.to.vect input=ihu_watershed type=area output=ihu_watershed --overwrite



# 3. TOPMODEL PARAMETERS
# suboutlets.txt created with divisions every 10% along lfp
v.segment input=ihu_lfp rules=suboutlets.txt output=ihu_suboutlets --overwrite
r.accumulate direction=ihu_fdir outlet=ihu_suboutlets subwatershed=ihu_subwatersheds --overwrite
d.erase
d.rast ihu_subwatersheds
d.vect ihu_lfp color=blue width=3
d.vect ihu_suboutlets fill_color=red icon=basic/circle size=10
d.vect ihu_streams

# Note that this subcatchment is really unevenly split (just like the online
# tutorial) and so should be modelled as a multi-subwatershed model with two
# separate r.topmodel models. However stick with one model for now, as with
# the tutorial.


# Creating the last set of the parameters input file
v.db.addtable map=ihu_lfp
v.to.db map=ihu_lfp option=length units=meters columns=length_m
v.db.select map=ihu_lfp
# Value we want is 2nd line when printed vertically
lfp_length=`v.db.select -c map=ihu_lfp format=vertical | sed -n '2p'`
echo $lfp_length

# The longest flow length is roughly 54,000 m. For each of 10 variable
# contributing areas, a distance of 54,000 m is accumulated.
v.db.addtable map=ihu_suboutlets
v.db.addcolumn map=ihu_suboutlets columns="distance_m real"
v.db.update map=ihu_suboutlets column=distance_m query_column="cat*$lfp_length/10"

# The cumulative area ratios of 10 subwatersheds can be obtained from the flow
# accumulation raster.
v.what.rast map=ihu_suboutlets raster=facc column=facc
v.what.rast map=ihu_outlet raster=facc column=facc
v.db.select map=ihu_outlet
# Value we want is 5th line when printed vertically
watershed_cells=`v.db.select -c map=ihu_outlet format=vertical | sed -n '5p'`
echo $watershed_cells

# The total number of cells within the watershed is 202684, stored in the
# watershed_cells script variable. Divide the facc column in the suboutlets
# vector by this number to obtain the cumulative area ratios.
v.db.addcolumn map=ihu_suboutlets columns="area_ratio real"
v.db.update map=ihu_suboutlets column=area_ratio query_column="1-facc/$watershed_cells."
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab
# Just make sure to append a . after $watershed_cells to force a floating-point
# division.

# Now modify topmodel input parameters template with these data
topmod_params_init='topmod_params_init.txt'
echo 'topmodel paramenters file used is' $topmod_params_init
# topmod_params_init is a template; simply add correct area on line 7 and area
# ratios First 6 lines the same for everything
head --lines 6 $topmod_params_init > topmod_params.txt
# Catchment area
r.stats -an ihu_watershed --quiet | awk '{print $2}' >> topmod_params.txt
# Next 54 lines of template same for everything
tail --lines 54 $topmod_params_init >> topmod_params.txt
echo "0.0       0.0" >> topmod_params.txt
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab >> topmod_params.txt
echo "$lfp_length       1.0" >> topmod_params.txt

# 4.TOPMODEL topidxstats
# r.topmodel provides a preprocessing flag -p to generate a topidxstats file
# from a topidx raster created by r.topidx. The following command calculates
# statistics about topographic indices in the topidx raster by splitting the
# entire range into 30 classes:
r.topmodel -p topidx=ihu_topidx ntopidxclasses=30 outtopidxstats=topidxstats.txt

# Each line starts with the upper limit of a topographic index range whose
# ratio is recorded in the next line in the second column with its lower
# limit in the first column. For example, topographic indices between 16.67
# and 17.09 covers the 1.742e-4% of the watershed.
#
# These pairs are sorted by the topographic index in an descending order.
# Since the first line represents the maximum topographic index, its second
# column must always be 0.

# 5. WEATHER DATA
# Taken from NCDC weather stations (which use Met Office ones) as should be
# easier to download. As the info is in a different projection system, need
# to create a different GRASS mapset to handle the data first.
# Also need to run the fetch_ghcnd_inventory.py, fetch_ncdc_prcp_stations.py
# and fetch_ncdc_evap_stations.py first which create various .db and 
# .json files with info. Remember to export the NCDC access token to Linux
# environment.
# Creating weather station vectors
#
# The coordinates of NCDC weather stations are in latitude and longitude,
# so we need to create a new latlong location in EPSG:4326. Open a new terminal.
#
# grass -c epsg:4326 grassdata/epsg4326
# 
# Import both ncdc_prcp_stations and ncdc_evap_stations. We will use data from
# January 1, 2010 to December 31, 2020.
#
# v.in.db table=ncdc_prcp_stations database=data.db x=longitude y=latitude z=elevation key=cat output=ncdc_prcp_stations where="id in (select id from ghcnd_inventory where datatypeid='PRCP' and minyear <= 2010 and maxyear >= 2019)" --overwrite
# v.in.db table=ncdc_evap_stations database=data.db x=longitude y=latitude z=elevation key=cat output=ncdc_evap_stations where="id in (select id from ghcnd_inventory where datatypeid='EVAP' and minyear <= 2010 and maxyear >= 2019)"
# Import the watershed vector from the Wader location. Tutorial recommends the
# watershed, but I'm going to use the whole region.
#
# v.proj location=epsg2240 input=watershed # Recommended
# v.proj location=uk input=whole_region@PERMANENT # Used this
#
# There are no EVAP stations, and 7 for whole Wader region, if I slightly
# expand the whole_region with a buffer.
# v.buffer -s input=whole_region output=whole_region_buff distance=0.1 --overwrite
#
# Let’s see which weather stations are within or close to the watershed. Create
# the Voronoi diagrams of ncdc_prcp_stations and ncdc_evap_stations, and select
# those stations within the Voronoi polygons. There are 116,459 points in
# ncdc_prcp_stations, but calculating their Voronoi polygons should not take
# long. It took about 34 seconds on my i5 laptop.
#
# g.region vect=whole_region_buff
# v.voronoi input=ncdc_prcp_stations output=ncdc_prcp_stations_voronoi # Used
# v.voronoi input=ncdc_evap_stations output=ncdc_evap_stations_voronoi # Not used
#
# v.select ainput=ncdc_prcp_stations_voronoi binput=whole_region_buff output=prcp_stations_voronoi # Used
# v.select ainput=ncdc_evap_stations_voronoi binput=watershed output=evap_stations_voronoi # Not used
# 
# v.select ainput=ncdc_prcp_stations binput=prcp_stations_voronoi output=prcp_stations # Used
# v.select ainput=ncdc_evap_stations binput=evap_stations_voronoi output=evap_stations # Not used
# Now go back to main Wader GRASS location
# v.proj location=epsg4326 mapset=PERMANENT input=prcp_stations_voronoi
# v.proj location=epsg4326 mapset=PERMANENT input=prcp_stations
# Now download the daily precipitation data
# tmod.ncdc prcp_voronoi=prcp_stations_voronoi_watershed evap_voronoi=evap_stations_voronoi_watershed start_date=2010-01-01 end_date=2020-12-31 output=input_evap.txt # Original
# tmod.ncdc.prcp prcp_voronoi=prcp_stations_voronoi start_date=2010-01-01 end_date=2019-12-31 output=input_evap.txt

# There are really too few weather NCDC stations in our area. Have created
# spatio-temporal daily temperature and rainfall datasets from UKHAD at 1 km
# from 2010 to 2019 (currently on bces-01 in uk_met mapset).
# Need to get average rainfall for target subcatchment ihu_watershed
#r.mapcalc expression="MASK=ihu_watershed" --overwrite
#g.region -a zoom=MASK res=1000
#t.rast.mapcalc inputs=wader_rainfall_daily@PERMANENT output=tmp_ihu_rainfall basename=tmp_ihu_rainfall expression="tmp_ihu_rainfall=wader_rainfall_daily" nprocs=4 --overwrite
#t.rast.univar -u tmp_ihu_rainfall | cut -d'|' -f4 > ihu_rainfall.txt 
#t.remove -d -f tmp_ihu_rainfall
#r.mask -r
# Convert rainfall to m / day
#awk '{printf("%.6f\n", ($1/1000))}' ihu_rainfall.txt > ihu_rainfall.txt2
#mv ihu_rainfall.txt2 ihu_rainfall.txt

# For PET use the USGS for now, but this is at 1-minute resolution. Might
# be possible to use EA PET data but this is England-only. Would need to
# create simple model to get it over the border, but in practice the PET
# is fairly uniform across the whole region on any given day so probably
# ok with USGS PET

# Centroid of whole Wader region in epsg4326 location; next only needs running
# once for whole Wader region as assume roughly the same in each subcatchment
# -2.4630233218518516,55.558426188481484
#for i in $(g.list type=raster pattern=et*); do
#    r.what map=$i coordinates=-2.4630233218518516,55.558426188481484 | sed 's/.*|/0.00001*/' | bc
#done > usgs_pet.txt

# Back in OS projection
# Best NRFA station is measuring Ettrick Water at Lindean id 21007
# Note: this actually runs to 30th Sept 2019 via rnrfa. NRFA website
# gives to current date, but on download also ends 30th Sept.
# See R script nrfa_download_flow.R for simple download of a station.
# saved in obs.txt to match tutorial
# Need to change to something easier later!
#nrfa_station_id=21007
#echo "# From nrfa_download_flow.R for $nrfa_station_id ideal start_date=2010-01-01 end_date=2020-12-31" > tmp.txt
#echo "# Q [m^3/d]" >> tmp.txt
#cat obs.txt >> tmp.txt
#mv tmp.txt obs.txt


# Need to assemble rainfall and PET into a single file
# original online tutorial creates a file called input_evap.txt for
# rainfall AND evapotranspiration. A bit confusing, so will rename
# later!
#rain_evap_file="input_evap.txt"
#echo "# Generated by from ihu_topmodel.bsh start_date=2010-01-01 end_date=2019-12-31" > $rain_evap_file
#echo "# dt [h]: Time step" >> $rain_evap_file
#echo "24" >> $rain_evap_file
#echo "" >> $rain_evap_file
#echo "################################################################################" >> $rain_evap_file
#echo "# R [m/dt]:  Rainfall" >> $rain_evap_file
#echo "# Ep [m/dt]: Potential evapotranspiration" >> $rain_evap_file
#echo "" >> $rain_evap_file
#echo "# R Ep" >> $rain_evap_file
#paste -d " " ihu_rainfall.txt usgs_pet.txt >> $rain_evap_file



# Calibration
# We just use the evap file, not pet
# As NRFA only goes to September 2019, use this as max date
# get the number of days for calibration period
#scripts/get_num_days.py 2010-01-01 2015-12-31
# Returns 2191
head -9 input_evap.txt > input_c_evap.txt
tail +10 input_evap.txt | sed '2191q' >> input_c_evap.txt
head -2 obs.txt > obs_c.txt
tail +3 obs.txt | sed '2191q' >> obs_c.txt
# For validation skip to january 1st 2015
#scripts/get_num_days.py 2010-01-01 2014-12-31
# Returns 1826
# Skip the first 1,826 records from input_evap.txt, input_pet.txt, and obs.txt.
# BUT the NRFA data sometimes incomplete, so have to check that filesizes
# match so need to check number of days to end of NRFA data
#get_num_days.py 2015-01-01 2019-09-30
# Returns 1734
head -9 input_evap.txt > input_v_evap.txt
tail +1836 input_evap.txt | sed '1734q' >> input_v_evap.txt
head -2 obs.txt > obs_v.txt
tail +1829 obs.txt | sed '1734q' >> obs_v.txt


# Before running the calibration script in the data folder copy the
# topmodel_params.txt to data/params.txt
