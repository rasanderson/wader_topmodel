#!/bin/bash

# Work on one Integrated Hydrological Unit using method
# from tutorial. Begin with headwater-based one (Ettrick
# Water, 332 G_NAME="Tweed (Source to Ettrick Water)") for
# simplicity.
# Express default region explictly (seems unreliable in GRASS 8.0)
g.region -a n=672200 s=568000 e=435400 w=301300 res=50 
r.mask -r

# Extract out Ettrick Water IHU
v.extract input=wader_ihu_groups output=ihu_target where="cat = 292" --overwrite
# Encountered problems creating reliable stream network from original DEM
# For Campy work used r.fill.dem first, just on the IHU (subcatchment for
# Campy. Try the same here.
# g.region vect=ihu_target
v.to.rast input=ihu_target output=MASK use=val value=1 --overwrite
g.region -a vect=ihu_target res=50
r.mapcalc expression=ihu_dem=ceh_ihdtm_50m --overwrite
r.colors map=ihu_dem color=elevation

# Clip out rivers
v.clip input=tweed_rivers clip=ihu_target output=ihu_rivers --overwrite

# Coords just downstream of NRFA 12 (21007)
# Use d.where | awk '{printf "%f\%f\point\n", $1, $2}' | v.in.ascii ...
# if using a d.mon screen
#
echo "348577.63|631535.35|point" | v.in.ascii input=- output=ihu_outlet columns='x double precision, y double precision, label varchar(20)' --overwrite
# Create stub to rivers and extend
v.db.addcolumn map=ihu_outlet columns="to_cat int"
v.distance from=ihu_outlet to=ihu_rivers output=ihu_outlet_to_rivers upload=cat column=to_cat --overwrite
# IMPORTANT. Due to a bug in GRASS #1408 the v.distance line does not work correctly. You
# must manually 
# Extract end node of connecting line
# db.droptable -f table=ihu_outlet_to_rivers
# v.db.addtable map=ihu_outlet_to_rivers
# v.to.points input=ihu_outlet_to_rivers layer=-1 use=end output=ihu_outlet_snapped_end --overwrite
# Change category numer from 2 to 1
# v.category input=ihu_outlet_snapped_end option=chlayer layer=2,1 output=ihu_outlet_snapped --overwrite


# Now we need to break the main stream network where are stub joins
# Read the stream category at the outlet.
v.db.select map=ihu_outlet columns=to_cat

# That is 10952 in the ihu_rivers vector.
# Create a new vector that contains the end node of this stream feature.
# Again, seems to be a bug in that v.segment does not create end point
# echo P 1 10952 100% | v.segment input=ihu_rivers output=ihu_stream_end --overwrite
# CLUNKY workaround
g.region vect=ihu_outlet_to_rivers
v.in.region output=tmp_region --overwrite
g.region vect=ihu_streams
v.buffer input=tmp_region output=tmp_region_buffer distance=10 --overwrite
v.clip input=ihu_streams clip=tmp_region_buffer output=ihu_streams_clip --overwrite
v.to.points input=ihu_streams_clip use=end output=ihu_stream_end --overwrite
v.to.points input=ihu_streams_clip use=start output=ihu_stream_end2 --overwrite


# Read the coordinates of the snapped outlet.
v.to.db -p map=ihu_outlet_snapped option=coor
# The outlet is at 348574.161543829|631541.683702573 
# Make a copy of ihu_rivers and break the stream at the outlet.
g.copy vector=ihu_rivers,ihu_streams --overwrite
v.edit map=ihu_streams tool=break coor=348574.161543829,631541.683702573

# We now read the coordinates at the stream end and break it off
# v.to.db -p map=ihu_stream_end option=coor
v.to.db -p map=ihu_stream_end2 option=coor
# The coordiates are 348564.16154383|631536.207512097. Delete the downstream
# piece of the stream. This edit will delete more features at the downstream
# side of the watershed, but that should be fine because we are only concerned
# with the upstream part of the stream network.
# NOTE: original version does not have id number in. This is needed as the cat
# number is not changed by the v.edit break earlier.
# Next line also not reliable
#v.edit map=ihu_streams tool=delete id=1390 coords=348564.16154383,631536.207512097

# Above process leaves two short detached bits of stream, but shouldn't be
# a problem as downstream of outlet.

# Compute weakly connected components in the stream network and find the
# component ID inside the watershed. For querying the component ID, use the
# coordinates of the snapped outlet.
v.net.components input=ihu_streams output=ihu_streams_net method=weak --overwrite
# Coords from ihu_outlet_snapped above 
v.what -ag map=ihu_streams_net coordinates=348574.161543829,631541.683702573| grep comp=

# The component ID of the stream network inside the watershed is 1. Extract
# this stream network.
v.extract input=ihu_streams_net where=comp=1 output=ihu_streams_watershed --overwrite

# Not sure if next is needed given good DEM (in theory) so comment out for
# now. Letâ€™s set the computational region that is big enough to contain the
# watershed.
# A buffer of 5,000 metres (100 times the 50m resolution) is used.
# g.region -a vector=ihu_streams_watershed n=n+5000 s=s-5000 e=e+5000 w=w-5000
# g.region -a vector=ihu_streams_watershed
# Check region with g.region -p as some strange rounding errors
# Clip CEH DEM to computational region
# r.mapcalc expression=ihu_dem=ceh_ihdtm_50m --overwrite

# Burn the stream network into the DEM and calculate flow directions. Unlike
# some other flow direction tools, r.watershed does not require sinks to be
# filled because it uses a least-cost algorithm.
# v.to.rast input=ihu_streams_watershed output=ihu_streams_watershed use=val
# r.mapcalc expression="ihu_dem_burned=if(isnull(ihu_streams_watershed),ihu_dem,-9999)"
#r.watershed elevation=ihu_dem_burned drainage=ihu_fdir stream=ihu_watershed_streams threshold=10 --overwrite
# r.watershed -s elevation=ihu_dem_burned drainage=ihu_fdir accumulation=ihu_facc direction=ihu_direction stream=ihu_watershed_streams threshold=25 --overwrite

# Now we can delineate the watershed and display the longest flow path
# Note: r.accumulate may neet to be installed with g.extension
# r.accumulate direction=ihu_fdir outlet=ihu_outlet_snapped subwatershed=ihu_watershed accumulation=ihu_facc longest_flow_path=ihu_lfp --overwrite
# Completely stuffs up as 50m misalignment
#echo "1|348275|631375|outlet" > ihu_output2.txt
#cat ihu_output2.txt | v.in.ascii in=- out=ihu_outlet2 x=2 y=3 cat=1 columns='cat int, x double precision, y double precision, label varchar(20)' --overwrite
#r.accumulate direction=ihu_fdir outlet=ihu_outlet2 subwatershed=ihu_watershed accumulation=ihu_facc longest_flow_path=ihu_lfp --overwrite
# r.accumulate direction=ihu_fdir subwatershed=ihu_watershed longest_flow_path=ihu_lfp coordinates=347825,630875 --overwrite

# Convert the watershed raster to vector.
# r.to.vect input=watershed type=area output=watershed

# Given problems with both stream network reliability from CEH and DEM, try
# filling and recreating.
g.region -a res=50
r.resamp.interp input=ihu_dem output=ihu_dem2 --overwrite
r.fill.dir input=ihu_dem output=ihu_demfill direction=ihu_demdir areas=ihu_dem_problems --overwrite
# If subcatch includes the River Tweed at its lower reaches, it is classed
# as -1000
r.mapcalc expression="ihu_demfill=if(ihu_demfill==-1000,null(),ihu_demfill)" --overwrite
r.colors ihu_demfill color=elevation

# generate shaded terrain for better visibility of results
r.relief input=ihu_demfill output=ihu_demfill_shade --overwrite
d.shade shade=ihu_demfill_shade color=ihu_demfill


# Now try and display streams
#r.watershed -s elevation=ihu_demfill drainage=ihu_fdir accumulation=ihu_facc stream=ihu_watershed_streams threshold=10000 --overwrite
r.stream.extract elevation=ihu_demfill stream_raster=ihu_watershed_streams direction=ihu_fdir threshold=1 --verbose --overwrite
d.rast ihu_watershed_streams
r.stream.order stream_rast=ihu_watershed_streams direction=ihu_fdir strahler=ihu_strahler horton=ihu_horton --overwrite
d.erase
d.rast ihu_strahler
d.rast ihu_horton

output_stream=`r.stats -n ihu_strahler | tail -1`
echo 'the highest stream number found is' $output_stream

r.mapcalc expression="output_stream_dem=if(ihu_strahler==$output_stream, ihu_demfill,null())" --overwrite
r.stats -gn output_stream_dem > output_flow.txt

# Assume output E and N coords are at minimum DEM of this stream
E_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $1}'`
N_outflow=`cat output_flow.txt | xargs -n3 | sort -nrk3,3 | tail -1 | awk '{print $2}'`

echo 'easting and northing coordinates for outflow are respectively' $E_outflow, $N_outflow
r.accumulate direction=ihu_fdir subwatershed=ihu_watershed accumulation=facc longest_flow_path=ihu_lfp coordinates=$E_outflow,$N_outflow --overwrite
d.vect ihu_streams
d.vect ihu_lfp color=blue width=5



# 2. TOPMODEL TOPOGRAPHIC INDEX
# ihu_demfill does not appear to be in metres (suspect it is in decimetres)
r.mapcalc expression="ihu_demfill=ihu_demfill/10"
r.topidx input=ihu_demfill output=ihu_topidx --overwrite
r.mapcalc expression="ihu_topidx_watershed=if(isnull(ihu_watershed),null(),ihu_topidx)" --overwrite
d.rast ihu_topidx_watershed
# NOTE: topidx_watershed is not calculated for reservoirs (flat areas)

# For later when setting up the topmodel_param.txt file we need the distance
# along each subwatershed. This needs the stream network to be 'burnt' into
# the relevant dem as per the tutorial.
# v.to.rast input=ihu_watershed_streams output=ihu_watershed_streams use=val --overwrite
r.mapcalc expression="ihu_dem_burned=if(isnull(ihu_watershed_streams),ihu_demfill,-9999)" --overwrite
r.watershed elevation=ihu_dem_burned drainage=fdir --overwrite

# Given problems with outlet map earlier, create one based on stream
# network outflow point
echo "1|$E_outflow|$N_outflow|output" | v.in.ascii in=- x=2 y=3 cat=1 columns='cat int, x double precision, y double precision, label varchar(20)' out=ihu_outlet --overwrite

# Now we can delineate the watershed and display the longest flow path
# Note: r.accumulate may neet to be installed with g.extension
r.accumulate direction=ihu_fdir outlet=ihu_outlet subwatershed=ihu_watershed accumulation=ihu_facc longest_flow_path=ihu_lfp --overwrite

# Convert the watershed raster to vector.
r.to.vect input=ihu_watershed type=area output=ihu_watershed --overwrite



# 3. TOPMODEL PARAMETERS
# suboutlets.txt created with divisions every 10% along lfp
v.segment input=ihu_lfp rules=suboutlets.txt output=ihu_suboutlets --overwrite
r.accumulate direction=ihu_fdir outlet=ihu_suboutlets subwatershed=ihu_subwatersheds --overwrite
d.erase
d.rast ihu_subwatersheds
d.vect ihu_lfp color=blue width=3
d.vect ihu_suboutlets fill_color=red icon=basic/circle size=10
d.vect ihu_streams

# Note that this subcatchment is really unevenly split (just like the online
# tutorial) and so should be modelled as a multi-subwatershed model with two
# separate r.topmodel models. However stick with one model for now, as with
# the tutorial.


# Creating the last set of the parameters input file
v.db.addtable map=ihu_lfp
v.to.db map=ihu_lfp option=length units=meters columns=length_m
v.db.select map=ihu_lfp
# Value we want is 2nd line when printed vertically
lfp_length=`v.db.select -c map=ihu_lfp format=vertical | sed -n '2p'`
echo $lfp_length

# The longest flow length is roughly 54,000 m. For each of 10 variable
# contributing areas, a distance of 54,000 m is accumulated.
v.db.addtable map=ihu_suboutlets
v.db.addcolumn map=ihu_suboutlets columns="distance_m real"
v.db.update map=ihu_suboutlets column=distance_m query_column="cat*$lfp_length/10"


# The cumulative area ratios of 10 subwatersheds can be obtained from the flow
# accumulation raster.
v.what.rast map=ihu_suboutlets raster=facc column=facc
v.what.rast map=ihu_outlet raster=facc column=facc
v.db.select map=ihu_outlet
# Value we want is 5th line when printed vertically
watershed_cells=`v.db.select -c map=ihu_outlet format=vertical | sed -n '5p'`
echo $watershed_cells

# The total number of cells within the watershed is 202684, stored in the
# watershed_cells script variable. Divide the facc column in the suboutlets
# vector by this number to obtain the cumulative area ratios.
v.db.addcolumn map=ihu_suboutlets columns="area_ratio real"
v.db.update map=ihu_suboutlets column=area_ratio query_column="1-facc/$watershed_cells."
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab
# Just make sure to append a . after $watershed_cells to force a floating-point
# division.

# Now modify topmodel input parameters template with these data
topmod_params_init='topmod_params_init.txt'
echo 'topmodel paramenters file used is' $topmod_params_init
# topmod_params_init is a template; simply add correct area on line 7 and area
# ratios First 6 lines the same for everything
head --lines 6 $topmod_params_init > topmod_params.txt
# Catchment area
r.stats -an ihu_watershed --quiet | awk '{print $2}' >> topmod_params.txt
# Next 54 lines of template same for everything
tail --lines 54 $topmod_params_init >> topmod_params.txt
echo "0.0       0.0" >> topmod_params.txt
v.db.select -c ihu_suboutlets columns=distance_m,area_ratio separator=tab >> topmod_params.txt
echo "$lfp_length       1.0" >> topmod_params.txt

# 4.TOPMODEL topidxstats
# r.topmodel provides a preprocessing flag -p to generate a topidxstats file
# from a topidx raster created by r.topidx. The following command calculates
# statistics about topographic indices in the topidx raster by splitting the
# entire range into 30 classes:
r.topmodel -p topidx=ihu_topidx ntopidxclasses=30 outtopidxstats=topidxstats.txt

# Each line starts with the upper limit of a topographic index range whose
# ratio is recorded in the next line in the second column with its lower
# limit in the first column. For example, topographic indices between 16.67
# and 17.09 covers the 1.742e-4% of the watershed.
#
# These pairs are sorted by the topographic index in an descending order.
# Since the first line represents the maximum topographic index, its second
# column must always be 0.

# 5. WEATHER DATA
# Taken from NCDC weather stations (which use Met Office ones) as should be
# easier to download. As the info is in a different projection system, need
# to create a different GRASS mapset to handle the data first.
# Also need to run the fetch_ghcnd_inventory.py, fetch_ncdc_prcp_stations.py
# and fetch_ncdc_evap_stations.py first which create various .db and 
# .json files with info. Remember to export the NCDC access token to Linux
# environment.
# Creating weather station vectors
#
# The coordinates of NCDC weather stations are in latitude and longitude,
# so we need to create a new latlong location in EPSG:4326. Open a new terminal.
#
# grass -c epsg:4326 grassdata/epsg4326
# 
# Import both ncdc_prcp_stations and ncdc_evap_stations. We will use data from
# January 1, 2010 to December 31, 2020.
#
# v.in.db table=ncdc_prcp_stations database=data.db x=longitude y=latitude z=elevation key=cat output=ncdc_prcp_stations where="id in (select id from ghcnd_inventory where datatypeid='PRCP' and minyear <= 2010 and maxyear >= 2019)" --overwrite
# v.in.db table=ncdc_evap_stations database=data.db x=longitude y=latitude z=elevation key=cat output=ncdc_evap_stations where="id in (select id from ghcnd_inventory where datatypeid='EVAP' and minyear <= 2010 and maxyear >= 2019)"
# Import the watershed vector from the Wader location. Tutorial recommends the
# watershed, but I'm going to use the whole region.
#
# v.proj location=epsg2240 input=watershed # Recommended
# v.proj location=uk input=whole_region@PERMANENT # Used this
#
# There are no EVAP stations, and 7 for whole Wader region, if I slightly
# expand the whole_region with a buffer.
# v.buffer -s input=whole_region output=whole_region_buff distance=0.1 --overwrite
#
# Letâ€™s see which weather stations are within or close to the watershed. Create
# the Voronoi diagrams of ncdc_prcp_stations and ncdc_evap_stations, and select
# those stations within the Voronoi polygons. There are 116,459 points in
# ncdc_prcp_stations, but calculating their Voronoi polygons should not take
# long. It took about 34 seconds on my i5 laptop.
#
# g.region vect=whole_region_buff
# v.voronoi input=ncdc_prcp_stations output=ncdc_prcp_stations_voronoi # Used
# v.voronoi input=ncdc_evap_stations output=ncdc_evap_stations_voronoi # Not used
#
# v.select ainput=ncdc_prcp_stations_voronoi binput=whole_region_buff output=prcp_stations_voronoi # Used
# v.select ainput=ncdc_evap_stations_voronoi binput=watershed output=evap_stations_voronoi # Not used
# 
# v.select ainput=ncdc_prcp_stations binput=prcp_stations_voronoi output=prcp_stations # Used
# v.select ainput=ncdc_evap_stations binput=evap_stations_voronoi output=evap_stations # Not used
# Now go back to main Wader GRASS location
# v.proj location=epsg4326 mapset=PERMANENT input=prcp_stations_voronoi
# v.proj location=epsg4326 mapset=PERMANENT input=prcp_stations
# Now download the daily precipitation data
# tmod.ncdc prcp_voronoi=prcp_stations_voronoi_watershed evap_voronoi=evap_stations_voronoi_watershed start_date=2010-01-01 end_date=2020-12-31 output=input_evap.txt # Original
# tmod.ncdc.prcp prcp_voronoi=prcp_stations_voronoi start_date=2010-01-01 end_date=2019-12-31 output=input_evap.txt

# There are really too few weather NCDC stations in our area. Have created
# spatio-temporal daily temperature and rainfall datasets from UKHAD at 1 km
# from 2010 to 2019 (currently on bces-01 in uk_met mapset).
# Need to get average rainfall for target subcatchment ihu_watershed
#r.mapcalc expression="MASK=ihu_watershed" --overwrite
#g.region -a zoom=MASK res=1000
#t.rast.mapcalc inputs=wader_rainfall_daily@PERMANENT output=tmp_ihu_rainfall basename=tmp_ihu_rainfall expression="tmp_ihu_rainfall=wader_rainfall_daily" nprocs=4 --overwrite
#t.rast.univar -u tmp_ihu_rainfall | cut -d'|' -f4 > ihu_rainfall.txt 
#t.remove -d -f tmp_ihu_rainfall
#r.mask -r
# Convert rainfall to m / day
#awk '{printf("%.6f\n", ($1/1000))}' ihu_rainfall.txt > ihu_rainfall.txt2
#mv ihu_rainfall.txt2 ihu_rainfall.txt

# For PET use the USGS for now, but this is at 1-minute resolution. Might
# be possible to use EA PET data but this is England-only. Would need to
# create simple model to get it over the border, but in practice the PET
# is fairly uniform across the whole region on any given day so probably
# ok with USGS PET

# Centroid of whole Wader region in epsg4326 location; next only needs running
# once for whole Wader region as assume roughly the same in each subcatchment
# -2.4630233218518516,55.558426188481484
#for i in $(g.list type=raster pattern=et*); do
#    r.what map=$i coordinates=-2.4630233218518516,55.558426188481484 | sed 's/.*|/0.00001*/' | bc
#done > usgs_pet.txt

# Back in OS projection
# Best NRFA station is measuring Ettrick Water at Lindean id 21007
# Note: this actually runs to 30th Sept 2019 via rnrfa. NRFA website
# gives to current date, but on download also ends 30th Sept.
# See R script nrfa_download_flow.R for simple download of a station.
# saved in obs.txt to match tutorial
# Need to change to something easier later!
#nrfa_station_id=21007
#echo "# From nrfa_download_flow.R for $nrfa_station_id ideal start_date=2010-01-01 end_date=2020-12-31" > tmp.txt
#echo "# Q [m^3/d]" >> tmp.txt
#cat obs.txt >> tmp.txt
#mv tmp.txt obs.txt


# Need to assemble rainfall and PET into a single file
# original online tutorial creates a file called input_evap.txt for
# rainfall AND evapotranspiration. A bit confusing, so will rename
# later!
#rain_evap_file="input_evap.txt"
#echo "# Generated by from ihu_topmodel.bsh start_date=2010-01-01 end_date=2019-12-31" > $rain_evap_file
#echo "# dt [h]: Time step" >> $rain_evap_file
#echo "24" >> $rain_evap_file
#echo "" >> $rain_evap_file
#echo "################################################################################" >> $rain_evap_file
#echo "# R [m/dt]:  Rainfall" >> $rain_evap_file
#echo "# Ep [m/dt]: Potential evapotranspiration" >> $rain_evap_file
#echo "" >> $rain_evap_file
#echo "# R Ep" >> $rain_evap_file
#paste -d " " ihu_rainfall.txt usgs_pet.txt >> $rain_evap_file



# Calibration
# We just use the evap file, not pet
# As NRFA only goes to September 2019, use this as max date
# get the number of days for calibration period
#scripts/get_num_days.py 2010-01-01 2015-12-31
# Returns 2191
head -9 input_evap.txt > input_c_evap.txt
tail +10 input_evap.txt | sed '2191q' >> input_c_evap.txt
head -2 obs.txt > obs_c.txt
tail +3 obs.txt | sed '2191q' >> obs_c.txt
# For validation skip to january 1st 2015
#scripts/get_num_days.py 2010-01-01 2014-12-31
# Returns 1826
# Skip the first 1,826 records from input_evap.txt, input_pet.txt, and obs.txt.
# BUT the NRFA data sometimes incomplete, so have to check that filesizes
# match so need to check number of days to end of NRFA data
#get_num_days.py 2015-01-01 2019-09-30
# Returns 1734
head -9 input_evap.txt > input_v_evap.txt
tail +1836 input_evap.txt | sed '1734q' >> input_v_evap.txt
head -2 obs.txt > obs_v.txt
tail +1829 obs.txt | sed '1734q' >> obs_v.txt


# Before running the calibration script in the data folder copy the
# topmodel_params.txt to data/params.txt
